# ğŸ§  Gesetzes-Chatbot (RAG-System)

Dieses Projekt ist ein **Retrieval-Augmented Generation (RAG)**-System, das auf lokal gespeicherten Gesetzestexten basiert.
Es kombiniert **Vektorsuche (ChromaDB)**, **lokale Embeddings (Ollama)** und **Antwortgenerierung via Together.ai (Mixtral-Modell)**.
Ãœber das mitgelieferte Frontend kann der Nutzer Fragen zu den enthaltenen PDFs stellen.

---

## ğŸ”§ Voraussetzungen

### ğŸ“¦ Software

- Python 3.10 oder 3.11
- Ollama (lokaler LLM/Embedding-Server)
- ChromaDB (Vektor-Datenbank, lokal)
- Together.ai API-Key (kostenlos)

### ğŸ“ Verzeichnisstruktur (Auszug)

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/               â†’ Originale PDFs
â”‚   â”œâ”€â”€ text/                â†’ Extrahierter Text
â”‚   â”œâ”€â”€ chunks/              â†’ TextblÃ¶cke (Chunks)
â”‚   â””â”€â”€ embeddings.json      â†’ Generierte Vektor-Daten
â”œâ”€â”€ scripts/                 â†’ Alle Python-Skripte
â”œâ”€â”€ Frontend/                â†’ HTML/CSS/JS-Frontend
â”œâ”€â”€ .env                     â†’ API-Key (nicht committen!)
```

---

## ğŸš€ Schritt-fÃ¼r-Schritt Inbetriebnahme (lokal)

### 1. Repository klonen

```bash
git clone https://github.com/dein-nutzername/dein-repository.git
cd dein-repository
```

### 2. Virtuelle Umgebung erstellen

```bash
python -m venv .venv
source .venv/Scripts/activate   # Windows
# source .venv/bin/activate     # macOS/Linux
```

### 3. AbhÃ¤ngigkeiten installieren

```bash
pip install -r requirements.txt
```

### 4. `.env`-Datei erstellen

```env
# Datei: .env
TOGETHER_API_KEY=sk-...dein-key...
```

> â— Die Datei `.env` ist **nicht im Repository enthalten** (siehe `.gitignore`).

---

## ğŸ” Daten vorbereiten

### 5. PDFs in den Ordner `data/input/` verschieben

Dann:

```bash
python scripts/extract_text.py
python scripts/chunk_text.py
python scripts/create_embeddings_json.py
```

---

## ğŸ§² Embeddings in Chroma laden

### 6. Starte Chroma (in neuem Terminal):

```bash
uvicorn chromadb.app:app --host 127.0.0.1 --port 8000
```

Dann in deinem alten Terminal:

```bash
python scripts/import_embeddings_to_chroma_server.py
```

---

## ğŸ§  Ollama starten (fÃ¼r Embeddings)

```bash
ollama run nomic-embed-text
```

---

## ğŸŒ Backend starten

```bash
python scripts/app.py
```

---

## ğŸ’¬ Frontend starten

1. Ã–ffne `Frontend/index.html` in VS Code
2. Rechtsklick â†’ **"Open with Live Server"**
3. Gib im Browser eine Frage ein (z.â€¯B. _â€Was steht im Arbeitsgesetz Ã¼ber Ruhezeiten?â€œ_)

---

## âœ… Beispielhafte Fragen

- â€Welche Ruhezeiten gelten bei Nachtarbeit?â€œ
- â€Was regelt das Datenschutzgesetz im ArbeitsverhÃ¤ltnis?â€œ
- â€Wie ist ein Werkvertrag im OR definiert?â€œ

---

## ğŸ›¡ Sicherheit

- API-Key liegt **nur in `.env`** und ist im `.gitignore` geschÃ¼tzt
- FÃ¼r Deployment wird empfohlen, den Key Ã¼ber Umgebungsvariablen zu setzen

---

## ğŸ§ª Weitere Skripte

| Script                                  | Beschreibung                          |
| --------------------------------------- | ------------------------------------- |
| `extract_text.py`                       | Extrahiert Text aus PDFs              |
| `chunk_text.py`                         | Teilt Text in Ã¼berlappende Chunks     |
| `create_embeddings_json.py`             | Erstellt Embeddings via Ollama        |
| `import_embeddings_to_chroma_server.py` | Importiert Embeddings in ChromaDB     |
| `app.py`                                | Flask-API zur Beantwortung von Fragen |

---
